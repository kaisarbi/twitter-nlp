{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Regular expression\n",
    "import re\n",
    "\n",
    "# Natural langage tool kit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# If you have never downloaded the list of stopwords plz feel free to uncomment this line\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tweet to lowercase\n",
    "def to_lower_case(tweet):\n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test lower case'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_lower_case('Test LOWER caSe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some chars at begining and the end of a tweet\n",
    "def process_begin_and_end(tweet):\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the Beging of the tweet is \" and white space'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_begin_and_end('\" the Beging of the tweet is \" and white space ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 2+ dots with a space\n",
    "\"\"\" \n",
    "re{ n,}\n",
    "Matches n or more occurrences of preceding expression.\n",
    "\"\"\"\n",
    "def process_dots(tweet):\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two dots '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_dots('Two dots...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 2+ spaces with a single one\n",
    "\"\"\"\n",
    "\\s = space\n",
    "\\s+ one or more space\n",
    "\"\"\"\n",
    "def process_spaces(tweet):\n",
    "    # Replace 2+ spaces with 1 space\n",
    "    tweet = re.sub(r'\\ {2,}', ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tweet with spaces'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_spaces('Tweet    with     spaces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers from a tweet\n",
    "\"\"\"\n",
    "\\d = any number\n",
    "\\D = anything but a number\n",
    "\"\"\"\n",
    "def process_numbers(tweet):\n",
    "    # Remove digits\n",
    "    tweet = re.sub(r'\\d', '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tweet with  numbers'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_numbers('Tweet with 2 numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tooked the stopwords of nltk library and removed some word with nuanced sens like 'no', 'dont' etc\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
    "             \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
    "             'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', \n",
    "             'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', \n",
    "             'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "             'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'of', 'at', \n",
    "             'by', 'for', 'with', 'about', 'between', 'into', 'through', 'during', 'before', 'after', 'above',\n",
    "             'below', 'to', 'from', 'up', 'down', 'in', 'on', 'under', 'again', 'further', 'then', 'once', \n",
    "             'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'other', 'some', \n",
    "             'such', 'own', 'same', 'so', 'than', 'too', 'will', 'just', 'now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all stop words from a tweet\n",
    "def process_stopwords(tweet):  \n",
    "    ''' Push stopwords to a set is more time efficient because complexity is O(1) '''\n",
    "    stop_words = set(stopwords)\n",
    "    tweet_words = tweet.split()\n",
    "    result_words  = [word for word in tweet_words if word.lower() not in stop_words]\n",
    "    tweet = ' '.join(result_words)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like nlp, not else'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_stopwords('i like doing some nlp, not else')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace URL with the word 'URL'\n",
    "def process_url(tweet):\n",
    "    regex_url = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    tweet = re.sub(regex_url, 'URL', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some links URL URL'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_url('some links https://pythonprogramming.net/ https://www.facebook.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repalce tags with the word 'USER_MENTION'\n",
    "def process_user_mention(tweet):\n",
    "    regex_user_mention = r'@[\\S]+'\n",
    "    tweet = re.sub(regex_user_mention, 'USER_MENTION', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USER_MENTION'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_user_mention('@happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hashtag and replace it with the word without the #\n",
    "def process_hashtag(tweet):\n",
    "    \"\"\"\n",
    "    tweet_words = tweet.split()\n",
    "    result_words = [word.strip(\"#\") for word in tweet_words]\n",
    "    tweet = ' '.join(result_words)\n",
    "    \"\"\"\n",
    "    regex_hashtag = r'#(\\S+)' #r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))#([A-Za-z]+[A-Za-z0-9-_]+)'\n",
    "    tweet = re.sub(regex_hashtag, r'\\1', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hashtag0 hashtag1 hashtag2 hashtag3'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_hashtag('#hashtag0 #hashtag1 #hashtag2 #hashtag3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove retweets\n",
    "\"\"\"\n",
    "\\b = space around whole words\n",
    "\"\"\"\n",
    "def process_retweet(tweet):\n",
    "    regex_retweet = r'\\brt\\b'\n",
    "    tweet = re.sub(regex_retweet, '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  retweet'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_retweet(' rt retweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "def process_punctuation(tweet):\n",
    "    # Remove , ; : . ? ! / from tweet\n",
    "    tweet = re.sub('[,;:.?!/]', '', string=tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It' a tweet with some punctuation \""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_punctuation('It\\' a tweet: with, some punctuation! :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify emojis into postive ad negative ones\n",
    "def process_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', 'EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a single word\n",
    "def process_word(word):\n",
    "    # Remove punctuation from the word\n",
    "    word = re.sub(r'[\\'\"?!,.():;]', '',word)\n",
    "    # Any character, except for a new line, one or more, \n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    # Remove - ' \" _ from the word\n",
    "    word = re.sub(r'[\\'\"-]', '', word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a word does not contain weird symboles\n",
    "def is_valid_word(word):\n",
    "    # Check if word begin with alphabet\n",
    "    return (re.search(r'^[a-zA-Z][a-zA-Z0-9\\._]*$',word) is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process words of a tweet\n",
    "def process_words(tweet):\n",
    "    processed_tweet = []\n",
    "    tweet_words = tweet.split()\n",
    "    for word in tweet_words:\n",
    "        if is_valid_word(word):\n",
    "            word = process_word(word)\n",
    "            processed_tweet.append(word)\n",
    "        else:\n",
    "            continue # goes to the next word\n",
    "    tweet = ' '.join(processed_tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    tweet = to_lower_case(tweet)\n",
    "    tweet = process_url(tweet)\n",
    "    tweet = process_user_mention(tweet)\n",
    "    tweet = process_hashtag(tweet)\n",
    "    tweet = process_retweet(tweet)\n",
    "    tweet = process_emojis(tweet)\n",
    "    tweet = process_numbers(tweet)\n",
    "    tweet = process_dots(tweet)\n",
    "    tweet = process_begin_and_end(tweet)\n",
    "    tweet = process_punctuation(tweet)\n",
    "    tweet = process_stopwords(tweet)\n",
    "    tweet = process_spaces(tweet)\n",
    "    tweet = process_words(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.82310390472412 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for i in range(len(df)):\n",
    "    df.at[i, 'tweet'] = process_tweet(df['tweet'][i])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_MENTION father dysfunctional selfish drags kids dysfunction run\n",
      "USER_MENTION USER_MENTION thanks lyft credit use cause offer wheelchair vans pdx disapointed getthanked\n",
      "bihday majesty\n",
      "model love u take u time\n",
      "factsguide society motivation\n",
      "huge fan fare big talking leave chaos pay disputes get allshowandnogo\n",
      "USER_MENTION camping tomorrow USER_MENTION USER_MENTION USER_MENTION USER_MENTION USER_MENTION USER_MENTION USER_MENTION\n",
      "next school year year think school exams hate imagine actorslife revolutionschool girl\n",
      "love land allin cavs champions cleveland clevelandcavaliers\n",
      "USER_MENTION USER_MENTION welcome gr\n",
      "ireland consumer price index climbed previous may blog silver gold forex\n",
      "selfish orlando standwithorlando pulseshooting orlandoshooting biggerproblems selfish heabreaking values love\n",
      "get see daddy today days gettingfed\n",
      "USER_MENTION cnn calls michigan middle school chant tcot\n",
      "comment australia opkillingbay seashepherd helpcovedolphins thecove helpcovedolphins\n",
      "ouch junior junior yugyoem omg\n",
      "thankful paner thankful positive\n",
      "retweet agree\n",
      "friday smiles around via ig user USER_MENTION cookies make people\n",
      "know essential oils made chemicals\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(df['tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 of June, 9 of August, 12 of Dec\n"
     ]
    }
   ],
   "source": [
    "# To well understand \\1 and \\2\n",
    "regex = r\"([a-zA-Z]+) (\\d+)\"\n",
    "\n",
    "# This will reorder the string and print:\n",
    "#   24 of June, 9 of August, 12 of Dec\n",
    "print(re.sub(regex, r\"\\2 of \\1\", \"June 24, August 9, Dec 12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following should all match:\n",
      "Value: :); Result: Matches!\n",
      "Value: :(; Result: Matches!\n",
      "Value: :):); Result: Matches!\n",
      "Value: :(:(; Result: Matches!\n",
      "Value: :):(; Result: Matches!\n",
      "\n",
      "The following should all not match:\n",
      "Value: ; Result: Doesn't match.\n",
      "Value: :(foo; Result: Doesn't match.\n",
      "Value: foo:(; Result: Doesn't match.\n",
      "Value: :( :(; Result: Doesn't match.\n",
      "Value: :( (; Result: Doesn't match.\n",
      "Value: :((; Result: Doesn't match.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "smiley_pattern = '^(:\\(|:\\))+$' # matches only the smileys \":)\" and \":(\"\n",
    "\n",
    "def test_match(s):\n",
    "    print('Value: %s; Result: %s' % (\n",
    "        s,\n",
    "        'Matches!' if re.match(smiley_pattern, s) else 'Doesn\\'t match.'\n",
    "    ))\n",
    "\n",
    "should_match = [\n",
    "    ':)',   # Single smile\n",
    "    ':(',   # Single frown\n",
    "    ':):)', # Two smiles\n",
    "    ':(:(', # Two frowns\n",
    "    ':):(', # Mix of a smile and a frown\n",
    "]\n",
    "should_not_match = [\n",
    "    '',         # Empty string\n",
    "    ':(foo',    # Extraneous characters appended\n",
    "    'foo:(',    # Extraneous characters prepended\n",
    "    ':( :(',    # Space between frowns\n",
    "    ':( (',     # Extraneous characters and space appended\n",
    "    ':(('       # Extraneous duplicate of final character appended\n",
    "]\n",
    "\n",
    "print('The following should all match:')\n",
    "for x in should_match: test_match(x);\n",
    "\n",
    "print('')   # Newline for output clarity\n",
    "\n",
    "print('The following should all not match:')\n",
    "for x in should_not_match: test_match(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
